PROJECT HEALTH AUDIT REPORT

IMPORTANT EXCLUSIONS:
- NEVER recommend CODEOWNERS or SECURITY.md files (governance decisions,
  not technical requirements)
- NEVER recommend deployment-specific workflows (deployment decisions,
  not technical requirements)

1. Executive Summary

Description: [Comprehensive analysis of [Project Name] [single app/monorepo]
demonstrating [key characteristics].]

Overall Score: [Score]/100 ([Label])

Top Strengths:
- [Strength 1]
- [Strength 2]
- [Strength 3]

Top Risks:
- [Risk 1]
- [Risk 2]
- [Risk 3]

Priority Recommendations:
1. [Recommendation 1]
2. [Recommendation 2]
3. [Recommendation 3]

2. At-a-Glance Scorecard

- Technology Stack & Config: [Score]/100 ([Label])     weight: 15%
- Architecture:              [Score]/100 ([Label])     weight: 18%
- Code Quality:              [Score]/100 ([Label])     weight: 15%
- Testing:                   [Score]/100 ([Label])     weight: 15%
- Security:                  [Score]/100 ([Label])     weight: 12%
- API & Data Layer:          [Score]/100 ([Label])     weight: 10%
- CI/CD:                     [Score]/100 ([Label])     weight:  5%
- Documentation:             [Score]/100 ([Label])     weight:  5%
- Developer Experience:      [Score]/100 ([Label])     weight:  5%
- Overall:                   [Score]/100 ([Label])

3. Technology Stack & Config

Description: [One-sentence description of the tech stack analysis].

Score: [Score]/100 ([Label])

Key Findings:
- [Finding 1]
- [Finding 2]
- [Finding 3]

Evidence:
- [File path or configuration reference]
- [Specific evidence item]

Risks:
- [Risk item 1]
- [Risk item 2]

Recommendations:
- [Recommendation 1]
- [Recommendation 2]

Counts & Metrics:
- [Metric name]: [Value]
- [Metric name]: [Value]

4. Architecture

Description: [One-sentence description of the architecture analysis].

Score: [Score]/100 ([Label])

Key Findings:
- [Finding 1]
- [Finding 2]
- [Finding 3]

Evidence:
- [File path or configuration reference]
- [Specific evidence item]

Risks:
- [Risk item 1]
- [Risk item 2]

Recommendations:
- [Recommendation 1]
- [Recommendation 2]

Counts & Metrics:
- [Metric name]: [Value]
- [Metric name]: [Value]

5. Code Quality

Description: [One-sentence description of the code quality analysis].

Score: [Score]/100 ([Label])

Key Findings:
- [Finding 1]
- [Finding 2]
- [Finding 3]

Evidence:
- [File path or configuration reference]
- [Specific evidence item]

Risks:
- [Risk item 1]
- [Risk item 2]

Recommendations:
- [Recommendation 1]
- [Recommendation 2]

Counts & Metrics:
- [Metric name]: [Value]
- [Metric name]: [Value]

6. Testing

Description: [One-sentence description of the testing analysis].

Score: [Score]/100 ([Label])

Key Findings:
- [Finding 1]
- [Finding 2]
- [Finding 3]

Evidence:
- [File path or configuration reference]
- [Specific evidence item]

Risks:
- [Risk item 1]
- [Risk item 2]

Recommendations:
- [Recommendation 1]
- [Recommendation 2]

Counts & Metrics:
- [Metric name]: [Value]
- [Metric name]: [Value]

7. Security

Description: [One-sentence description of the security analysis].

Score: [Score]/100 ([Label])

Key Findings:
- [Finding 1]
- [Finding 2]
- [Finding 3]

Evidence:
- [File path or configuration reference]
- [Specific evidence item]

Risks:
- [Risk item 1]
- [Risk item 2]

Recommendations:
- [Recommendation 1]
- [Recommendation 2]

Counts & Metrics:
- [Metric name]: [Value]
- [Metric name]: [Value]

8. API & Data Layer

Description: [One-sentence description of the API and data layer analysis].

Score: [Score]/100 ([Label])

Key Findings:
- [Finding 1]
- [Finding 2]
- [Finding 3]

Evidence:
- [File path or configuration reference]
- [Specific evidence item]

Risks:
- [Risk item 1]
- [Risk item 2]

Recommendations:
- [Recommendation 1]
- [Recommendation 2]

Counts & Metrics:
- [Metric name]: [Value]
- [Metric name]: [Value]

9. CI/CD

Description: [One-sentence description of the CI/CD analysis].

Score: [Score]/100 ([Label])

Key Findings:
- [Finding 1]
- [Finding 2]
- [Finding 3]

Evidence:
- [File path or configuration reference]
- [Specific evidence item]

Risks:
- [Risk item 1]
- [Risk item 2]

Recommendations:
- [Recommendation 1]
- [Recommendation 2]

Counts & Metrics:
- [Metric name]: [Value]
- [Metric name]: [Value]

10. Documentation

Description: [One-sentence description of the documentation analysis].

Score: [Score]/100 ([Label])

Key Findings:
- [Finding 1]
- [Finding 2]
- [Finding 3]

Evidence:
- [File path or configuration reference]
- [Specific evidence item]

Risks:
- [Risk item 1]
- [Risk item 2]

Recommendations:
- [Recommendation 1]
- [Recommendation 2]

Counts & Metrics:
- [Metric name]: [Value]
- [Metric name]: [Value]

11. Developer Experience

Description: [One-sentence description of the developer experience analysis].

Score: [Score]/100 ([Label])

Key Findings:
- [Finding 1]
- [Finding 2]
- [Finding 3]

Evidence:
- [File path or configuration reference]
- [Specific evidence item]

Risks:
- [Risk item 1]
- [Risk item 2]

Recommendations:
- [Recommendation 1]
- [Recommendation 2]

12. Quality Index

Summary of all section scores with interpretation:

- Technology Stack & Config: [Score]/100 ([Label]) -- [one-line interpretation]
- Architecture:              [Score]/100 ([Label]) -- [one-line interpretation]
- Code Quality:              [Score]/100 ([Label]) -- [one-line interpretation]
- Testing:                   [Score]/100 ([Label]) -- [one-line interpretation]
- Security:                  [Score]/100 ([Label]) -- [one-line interpretation]
- API & Data Layer:          [Score]/100 ([Label]) -- [one-line interpretation]
- CI/CD:                     [Score]/100 ([Label]) -- [one-line interpretation]
- Documentation:             [Score]/100 ([Label]) -- [one-line interpretation]
- Developer Experience:      [Score]/100 ([Label]) -- [one-line interpretation]

Overall: [Score]/100 ([Label])

13. Risks & Opportunities

Top Risks:
1. [Risk with context and impact]
2. [Risk with context and impact]
3. [Risk with context and impact]

Top Opportunities:
1. [Opportunity with expected benefit]
2. [Opportunity with expected benefit]
3. [Opportunity with expected benefit]

14. Recommendations

Prioritized, actionable recommendations:

HIGH PRIORITY (address immediately):
1. [Recommendation with specific action and expected impact]
2. [Recommendation with specific action and expected impact]
3. [Recommendation with specific action and expected impact]

MEDIUM PRIORITY (address within sprint):
1. [Recommendation]
2. [Recommendation]
3. [Recommendation]

LOW PRIORITY (address when possible):
1. [Recommendation]
2. [Recommendation]

15. Appendix: Evidence Index

Files and references organized by area:

Technology Stack:
- [file path: what was found]

Architecture:
- [file path: what was found]

Code Quality:
- [file path: what was found]

Testing:
- [file path: what was found]

Security:
- [file path: what was found]

CI/CD:
- [file path: what was found]

Documentation:
- [file path: what was found]
